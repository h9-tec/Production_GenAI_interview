[← Back to Main](../README.md) | [← Previous: Red Flags](./red-flags.md)

---

# Resources

A curated collection of papers, courses, tutorials, tools, and community resources covering all 16 sections of this guide.

---

## Comprehensive Courses

> Full courses covering multiple topics in this guide.

| Course | Platform | Topics Covered |
|:---|:---|:---|
| [Retrieval Augmented Generation (RAG)](https://www.deeplearning.ai/courses/retrieval-augmented-generation-rag/) | DeepLearning.AI | RAG architecture, vector DBs, hybrid search, evaluation |
| [Building and Evaluating Advanced RAG](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/) | DeepLearning.AI | Advanced RAG patterns, evaluation metrics |
| [Generative AI with Large Language Models](https://learn.deeplearning.ai/courses/generative-ai-with-llms/information) | DeepLearning.AI / Coursera | LLM fundamentals, fine-tuning, deployment |
| [Generative AI Engineering with LLMs Specialization](https://www.coursera.org/specializations/generative-ai-engineering-with-llms) | Coursera | End-to-end LLM engineering |
| [AI Agents with LangChain and LangGraph](https://www.udacity.com/course/ai-agents-with-langchain-and-langgraph--cd13764) | Udacity | Agents, tool use, LangGraph |
| [LLM Engineering, RAG, & AI Agents Masterclass](https://www.udemy.com/course/become-an-llm-agentic-ai-engineer-14-day-bootcamp-2025/) | Udemy | RAG, agents, CrewAI, LangGraph, AutoGen |
| [AI Engineer Core Track: LLM Engineering, RAG, QLoRA, Agents](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) | Udemy | LLM engineering, RAG, fine-tuning, agents |
| [The Complete Agentic AI Engineering Course](https://www.udemy.com/course/the-complete-agentic-ai-engineering-course/) | Udemy | OpenAI Agents SDK, CrewAI, LangGraph, MCP |
| [12 Best RAG Courses](https://www.classcentral.com/report/best-rag-courses/) | Class Central | Curated list of RAG courses |
| [7 Free Courses to Master RAG](https://www.turingpost.com/p/7-free-courses-to-master-rag) | Turing Post | Free RAG learning paths |

---

## Section 01 — RAG Systems

### Papers
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) — Lewis et al. (2020). The original RAG paper.
- [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511) — Asai et al. (2023). Adaptive retrieval with reflection tokens.
- [A Systematic Review of Key RAG Systems: Progress, Gaps, and Future Directions](https://arxiv.org/html/2507.18910v1) — Comprehensive 2025 RAG survey.
- [Retrieval-Augmented Generation: A Comprehensive Survey](https://arxiv.org/html/2506.00054v1) — RAG architectures, enhancements, and robustness frontiers.

### Courses & Tutorials
- [Retrieval Augmented Generation (RAG) — DeepLearning.AI](https://www.deeplearning.ai/courses/retrieval-augmented-generation-rag/) — Free course by Zain Hasan covering architecture to deployment.
- [Building and Evaluating Advanced RAG — DeepLearning.AI](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/) — Advanced RAG patterns and evaluation.
- [Free RAG Course Review](https://www.kzsoftworks.com/blog/free-rag-course-deeplearning-ai-review) — Detailed review of the DeepLearning.AI RAG course.
- [Free LLM and GenAI Courses (2025)](https://www.evidentlyai.com/blog/llm-genai-courses) — Curated list including RAG courses.

### Frameworks
- [LangChain](https://github.com/langchain-ai/langchain) — Popular LLM application framework with RAG support.
- [LlamaIndex](https://github.com/run-llama/llama_index) — Data framework for LLM applications, RAG-focused.
- [Haystack](https://github.com/deepset-ai/haystack) — End-to-end NLP framework for RAG pipelines.
- [Self-RAG Project Page](https://selfrag.github.io/) — Official Self-RAG implementation and demo.

---

## Section 02 — Chunking Strategies

### Articles & Tutorials
- [Chunking Strategies to Improve RAG Pipeline Performance — Weaviate](https://weaviate.io/blog/chunking-strategies-for-rag) — Comprehensive overview of chunking methods.
- [Ultimate Guide to Chunking Strategies — Databricks](https://community.databricks.com/t5/technical-blog/the-ultimate-guide-to-chunking-strategies-for-rag-applications/ba-p/113089) — Enterprise-focused chunking guide.
- [Chunking Strategies for AI and RAG — DataCamp](https://www.datacamp.com/blog/chunking-strategies) — Beginner-friendly guide.
- [Chunking Strategies for RAG with LangChain — IBM](https://www.ibm.com/think/tutorials/chunking-strategies-for-rag-with-langchain-watsonx-ai) — Hands-on tutorial with LangChain.
- [Best Chunking Strategies for RAG in 2025 — Firecrawl](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025) — Updated 2025 best practices.
- [Semantic Chunking for RAG — Medium](https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5) — Deep dive into semantic chunking.
- [9 Chunking Strategies to Improve RAG Performance](https://www.nb-data.com/p/9-chunking-strategis-to-improve-rag) — Practical comparison of 9 approaches.
- [7 Chunking Techniques That Work](https://www.f22labs.com/blogs/7-chunking-strategies-in-rag-you-need-to-know/) — Implementation-focused guide.
- [Ultimate Guide for Chunking Strategies — Agenta](https://agenta.ai/blog/the-ultimate-guide-for-chunking-strategies) — Decision framework for choosing strategies.

---

## Section 03 — Embeddings & Vector Databases

### Courses
- [Mastering Vector Databases & Embedding Models](https://www.udemy.com/course/mastering-vector-databases-embedding-models-in-2025/) — Udemy, covers HNSW, IVF, semantic search, RAG.
- [Vector Databases Deep Dive — Coursera](https://www.coursera.org/learn/packt-vector-databases-deep-dive-y4haf) — Principles, applications, and future trends.
- [Vector Databases: From Embeddings to Applications — Educative](https://www.educative.io/courses/vector-database) — Hands-on with HNSW.
- [Embedding Models: From Architecture to Implementation — DeepLearning.AI](https://www.deeplearning.ai/courses/) — Understanding embedding architectures.
- [Large Language Models with Semantic Search — DeepLearning.AI](https://www.deeplearning.ai/courses/) — Dense vectors and search.

### Articles & Tutorials
- [Complete Guide to Vector Databases — Machine Learning Mastery](https://machinelearningmastery.com/the-complete-guide-to-vector-databases-for-machine-learning/) — Comprehensive guide.
- [HNSW Indexing Fundamentals — Qdrant](https://qdrant.tech/course/essentials/day-2/what-is-hnsw/) — Deep dive into HNSW algorithm.
- [Vector Database Basics: HNSW — Tiger Data](https://www.tigerdata.com/blog/vector-database-basics-hnsw) — Visual explanation of HNSW.
- [Deep Dive on Vector Databases — Daily Dose of DS](https://www.dailydoseofds.com/a-beginner-friendly-and-comprehensive-deep-dive-on-vector-databases/) — Beginner-friendly overview.
- [Vector Databases Lecture — Cornell CS4414](https://www.cs.cornell.edu/courses/cs4414/2025fa/Slides/24-Vector%20Databases.pdf) — Academic lecture slides.

### Tools
- [Pinecone](https://www.pinecone.io/) — Managed vector database.
- [Weaviate](https://github.com/weaviate/weaviate) — Open-source vector database with hybrid search.
- [Qdrant](https://github.com/qdrant/qdrant) — High-performance vector similarity search.
- [pgvector](https://github.com/pgvector/pgvector) — Vector similarity search for PostgreSQL.
- [Milvus](https://github.com/milvus-io/milvus) — Cloud-native vector database.

---

## Section 04 — Hybrid Search & Reranking

### Articles & Tutorials
- [Integrating BM25 in Hybrid Search and Reranking Pipelines — DEV](https://dev.to/negitamaai/integrating-bm25-in-hybrid-search-and-reranking-pipelines-strategies-and-applications-4joi) — Comprehensive BM25 + vector pipeline guide.
- [Reranking in Hybrid Search — Qdrant](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/) — Official Qdrant tutorial.
- [Hybrid Search Revamped — Qdrant](https://qdrant.tech/articles/hybrid-search/) — Building with Qdrant's Query API.
- [Optimizing RAG with Hybrid Search & Reranking — VectorHub](https://superlinked.com/vectorhub/articles/optimizing-rag-with-hybrid-search-reranking) — Production optimization guide.
- [Advanced RAG: From Naive to Hybrid Search — DEV](https://dev.to/kuldeep_paul/advanced-rag-from-naive-retrieval-to-hybrid-search-and-re-ranking-4km3) — Step-by-step progression.
- [Hybrid Search + Reranking in Practice — Medium](https://medium.com/@ghitahouiralami/hybrid-search-reranking-in-practice-turbopuffer-zeroentropy-5ceae7200bfc) — Real-world implementation.
- [Hybrid Retrieval and Reranking in RAG — Genzeon](https://www.genzeon.com/hybrid-retrieval-deranking-in-rag-recall-precision/) — Dual-stage approach for recall and precision.

### Tools
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) — Embeddings and cross-encoder reranking models.
- [rank_bm25](https://github.com/dorianbrown/rank_bm25) — Python BM25 implementation.
- [Cohere Rerank](https://cohere.com/rerank) — Production reranking API.

---

## Section 05 — Semantic Caching

### Papers
- [GPTCache: An Open-Source Semantic Cache for LLM Applications](https://aclanthology.org/2023.nlposs-1.24/) — ACL 2023 paper.
- [GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic Embedding Caching](https://arxiv.org/html/2411.05276v1) — Cost reduction via semantic caching.
- [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/html/2602.13165v1) — 2025 advanced caching architecture.
- [A Generative Caching System for Large Language Models](https://arxiv.org/html/2503.17603v1) — Novel generative caching approach.

### Tools & Tutorials
- [GPTCache — GitHub](https://github.com/zilliztech/GPTCache) — Semantic cache for LLMs, integrated with LangChain and LlamaIndex.
- [GPTCache Documentation](https://gptcache.readthedocs.io/) — Official docs and usage guide.
- [GPTCache Tutorial — DataCamp](https://www.datacamp.com/tutorial/gptcache-tutorial-enhancing-efficiency-in-llm-applications) — Hands-on tutorial.

---

## Section 06 — Multi-Agent Systems

### Courses
- [Design, Develop, and Deploy Multi-Agent Systems with CrewAI — DeepLearning.AI](https://www.deeplearning.ai/courses/) — Multi-agent design patterns.
- [DSPy: Build and Optimize Agentic Apps — DeepLearning.AI](https://www.deeplearning.ai/courses/) — Agentic applications with DSPy.
- [AI Agents with LangChain and LangGraph — Udacity](https://www.udacity.com/course/ai-agents-with-langchain-and-langgraph--cd13764) — Production agent systems.

### Articles & Comparisons
- [Multi-Agent AI Systems: LangGraph vs CrewAI vs AutoGen (2026)](https://www.mayhemcode.com/2026/02/multi-agent-ai-systems-explained.html) — Comprehensive framework comparison.
- [CrewAI vs LangGraph vs AutoGen — DataCamp](https://www.datacamp.com/tutorial/crewai-vs-langgraph-vs-autogen) — Side-by-side comparison.
- [Open Source AI Agent Frameworks Compared (2026)](https://openagents.org/blog/posts/2026-02-23-open-source-ai-agent-frameworks-compared) — Including OpenAgents.
- [Top AI Agent Frameworks in 2025 — Codecademy](https://www.codecademy.com/article/top-ai-agent-frameworks-in-2025) — Framework overview.

### Frameworks
- [LangGraph](https://github.com/langchain-ai/langgraph) — Stateful multi-agent workflows.
- [CrewAI](https://github.com/crewAIInc/crewAI) — Role-based multi-agent orchestration.
- [AutoGen](https://github.com/microsoft/autogen) — Microsoft's multi-agent conversation framework.
- [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) — Official OpenAI agent framework.

---

## Section 07 — Function Calling & Tool Use

### Official Documentation
- [Function Calling — OpenAI API](https://platform.openai.com/docs/guides/function-calling) — Official guide.
- [Function Calling in the OpenAI API — Help Center](https://help.openai.com/en/articles/8555517-function-calling-in-the-openai-api) — Getting started guide.

### Tutorials
- [Function Calling with LLMs — Prompt Engineering Guide](https://www.promptingguide.ai/applications/function_calling) — Concepts and use cases.
- [OpenAI Function Calling Tutorial — Vellum](https://www.vellum.ai/blog/openai-function-calling-tutorial) — Step-by-step setup.
- [Guide to Function Calling in OpenAI — Mirascope](https://mirascope.com/blog/openai-function-calling) — Comprehensive guide.
- [LLM Basics: OpenAI Function Calling — Caktus](https://www.caktusgroup.com/blog/2025/12/01/learning-llm-basics-openai-function-calling/) — Practical examples (2025).
- [How Tools Are Called in AI Agents — Medium](https://medium.com/@sayalisureshkumbhar/how-tools-are-called-in-ai-agents-complete-2025-guide-with-examples-42dcdfe6ba38) — Complete 2025 guide.
- [Functions, Tools and Agents with LangChain — DeepLearning.AI](https://www.deeplearning.ai/courses/) — Short course on tool integration.

---

## Section 08 — Arabic NLP Challenges

### Papers
- [AraToken: Optimizing Arabic Tokenization](https://arxiv.org/html/2512.18399v1) — 18% lower fertility through normalization pipeline.
- [The Landscape of Arabic Large Language Models](https://cacm.acm.org/arab-world-regional-special-section/the-landscape-of-arabic-large-language-models/) — CACM survey of Arabic LLMs.
- [Evaluating Arabic LLMs: Benchmarks, Methods, and Gaps](https://arxiv.org/html/2510.13430v1) — Comprehensive evaluation survey.
- [AraLingBench: Human-Annotated Benchmark for Arabic LLMs](https://arxiv.org/html/2511.14295v2) — Arabic linguistic capabilities benchmark.
- [Cross-Dialectal Arabic Translation](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1661789/full) — LLM comparison for dialect translation.
- [Emerging Techniques in Arabic NLP (2025)](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1715520/full) — Frontiers editorial on Arabic NLP advances.
- [Exploring Tokenization Strategies for Arabic](https://arxiv.org/pdf/2403.11130) — Tokenization and vocabulary analysis.

### Tools & Models
- [CAMeL Tools — GitHub](https://github.com/CAMeL-Lab/camel_tools) — Arabic NLP toolkit by NYU Abu Dhabi.
- [CAMeL Tools Paper — ACL](https://aclanthology.org/2020.lrec-1.868/) — Open source Python toolkit for Arabic NLP.
- [Jais — Cerebras](https://www.cerebras.ai/blog/jais-a-new-pinnacle-in-open-arabic-nlp) — 13B parameter Arabic-English LLM.
- [ArabicNLP 2025 Shared Task](https://nadi.dlnlp.ai/2025/) — Multidialectal Arabic speech processing.

---

## Section 09 — LLM Deployment & Inference

### Documentation & Tutorials
- [vLLM Quantization Guide](https://docs.vllm.ai/en/latest/features/quantization/) — Official vLLM quantization docs.
- [Complete Guide to LLM Quantization with vLLM](https://docs.jarvislabs.ai/blog/vllm-quantization-complete-guide-benchmarks) — Benchmarks and best practices.
- [Serving LLMs with vLLM — Nebius](https://nebius.com/blog/posts/serving-llms-with-vllm-practical-guide) — Practical inference guide.
- [Accelerating LLM Inference with AWQ and GPTQ — AWS](https://aws.amazon.com/blogs/machine-learning/accelerating-llm-inference-with-post-training-weight-and-activation-using-awq-and-gptq-on-amazon-sagemaker-ai/) — Production deployment on SageMaker.
- [Practical Guide to LLM Quantization Methods — Cast AI](https://cast.ai/blog/demystifying-quantizations-llms/) — GPTQ vs AWQ vs GGUF comparison.
- [Speeding Up LLMs: GPTQ and AWQ Deep Dive — Medium](https://medium.com/@kimdoil1211/speeding-up-large-language-models-a-deep-dive-into-gptq-and-awq-quantization-0bb001eaabd4) — Technical deep dive.

### Tools
- [vLLM](https://github.com/vllm-project/vllm) — High-throughput LLM serving with PagedAttention.
- [llm-compressor](https://github.com/vllm-project/llm-compressor) — Model compression for vLLM deployment.
- [Text Generation Inference (TGI)](https://github.com/huggingface/text-generation-inference) — Hugging Face's production inference server.
- [Ollama](https://github.com/ollama/ollama) — Run LLMs locally.

---

## Section 10 — Fine-tuning

### Tutorials & Guides
- [Fine-tuning LLMs Guide — Unsloth](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide) — Official Unsloth documentation.
- [LoRA Hyperparameters Guide — Unsloth](https://unsloth.ai/docs/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide) — Practical hyperparameter tuning.
- [QLoRA Fine-Tuning with Unsloth — Medium](https://medium.com/@matteo28/qlora-fine-tuning-with-unsloth-a-complete-guide-8652c9c7edb3) — Complete guide.
- [How to Fine-Tune an LLM with Unsloth — NVIDIA](https://blogs.nvidia.com/blog/rtx-ai-garage-fine-tuning-unsloth-dgx-spark/) — NVIDIA's official guide.
- [Unsloth Guide — DataCamp](https://www.datacamp.com/tutorial/unsloth-guide-optimize-and-speed-up-llm-fine-tuning) — Optimize and speed up fine-tuning.
- [Fine-Tuning Llama 3 with LoRA — Neptune.ai](https://neptune.ai/blog/fine-tuning-llama-3-with-lora) — Step-by-step guide.
- [SFT with QLoRA on Unsloth for Text-to-SQL — Medium](https://medium.com/@jennytan5522/supervised-fine-tuning-sft-with-qlora-on-unsloth-for-text-to-sql-69ea3265de64) — Applied fine-tuning example.
- [Unsloth: From Basics to Vision Model Fine-Tuning — LearnOpenCV](https://learnopencv.com/unsloth-guide-efficient-llm-fine-tuning/) — Comprehensive guide.

### Tools
- [Unsloth](https://unsloth.ai/) — 2-5x faster fine-tuning, 70-80% less memory.
- [PEFT](https://github.com/huggingface/peft) — Hugging Face parameter-efficient fine-tuning.
- [TRL](https://github.com/huggingface/trl) — Transformer reinforcement learning.

---

## Section 11 — Evaluation & Metrics

### Tools & Documentation
- [RAGAS Metrics Documentation](https://docs.ragas.io/en/latest/concepts/metrics/) — Official metrics reference.
- [RAGAS: Align LLM as Judge](https://docs.ragas.io/en/stable/howtos/applications/align-llm-as-judge/) — LLM-as-judge alignment guide.
- [DeepEval RAGAS Integration](https://deepeval.com/docs/metrics-ragas) — Using RAGAS metrics in DeepEval.
- [DeepEval RAG Evaluation Guide](https://deepeval.com/guides/guides-rag-evaluation) — Comprehensive RAG evaluation.
- [DeepEval Faithfulness Metric](https://deepeval.com/docs/metrics-faithfulness) — Faithfulness measurement.

### Articles
- [RAG Evaluation Metrics Best Practices — Patronus](https://www.patronus.ai/llm-testing/rag-evaluation-metrics) — Production evaluation guide.
- [RAG Evaluation Metrics: Answer Relevancy, Faithfulness, and More — Confident AI](https://www.confident-ai.com/blog/rag-evaluation-metrics-answer-relevancy-faithfulness-and-more) — Detailed metric breakdown.
- [Evaluating RAG Systems in 2025 — Cohorte](https://www.cohorte.co/blog/evaluating-rag-systems-in-2025-ragas-deep-dive-giskard-showdown-and-the-future-of-context) — RAGAS deep dive and comparisons.
- [LLM Evaluation in 2025 — Medium](https://medium.com/@QuarkAndCode/llm-evaluation-in-2025-metrics-rag-llm-as-judge-best-practices-ad2872cfa7cb) — Metrics, RAG, LLM-as-Judge best practices.

### Frameworks
- [RAGAS](https://github.com/explodinggradients/ragas) — RAG evaluation framework.
- [DeepEval](https://github.com/confident-ai/deepeval) — LLM evaluation framework.
- [Langfuse](https://github.com/langfuse/langfuse) — LLM observability with evaluation.
- [Arize Phoenix](https://github.com/Arize-ai/phoenix) — AI observability and evaluation.

---

## Section 12 — Guardrails & Security

### Official Resources
- [OWASP Top 10 for LLM Applications 2025 (PDF)](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf) — Official 2025 guide.
- [OWASP LLM01:2025 Prompt Injection](https://genai.owasp.org/llmrisk/llm01-prompt-injection/) — Detailed prompt injection risk.
- [OWASP LLM Prompt Injection Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/LLM_Prompt_Injection_Prevention_Cheat_Sheet.html) — Defense strategies.
- [OWASP Top 10 for LLMs — Promptfoo](https://www.promptfoo.dev/docs/red-team/owasp-llm-top-10/) — Red-teaming guide.

### Articles
- [LLM Security: Prompt Injection Defense for Production — Introl](https://introl.com/blog/llm-security-prompt-injection-defense-production-guide-2025) — Production defense guide (2025).
- [OWASP Top 10 for LLMs: Key Risks and Mitigation — Invicti](https://www.invicti.com/blog/web-security/owasp-top-10-risks-llm-security-2025) — Risk mitigation strategies.
- [OWASP Top 10 for LLMs — DeepTeam](https://www.trydeepteam.com/docs/frameworks-owasp-top-10-for-llms) — Red-teaming framework.

### Tools
- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) — NVIDIA's programmable guardrails framework.
- [Promptfoo](https://github.com/promptfoo/promptfoo) — LLM red-teaming and evaluation.
- [Guardrails AI](https://github.com/guardrails-ai/guardrails) — Input/output guardrails for LLMs.

---

## Section 13 — Cost Optimization

### Articles & Guides
- [LLM Cost Optimization: Reduce AI Expenses by 80%](https://ai.koombea.com/blog/llm-cost-optimization) — Comprehensive strategies.
- [Reduce LLM Costs: Token Optimization Strategies](https://www.glukhov.org/post/2025/11/cost-effective-llm-applications/) — Practical token optimization.
- [Technical Guide to Managing LLM Costs — Maxim](https://www.getmaxim.ai/articles/the-technical-guide-to-managing-llm-costs-strategies-for-optimization-and-roi/) — ROI-focused guide.
- [Prompt Caching: 10x Cheaper LLM Tokens — ngrok](https://ngrok.com/blog/prompt-caching/) — Deep dive into prompt caching.
- [Prompt Caching: 60% Cost Reduction — Thomson Reuters](https://medium.com/tr-labs-ml-engineering-blog/prompt-caching-the-secret-to-60-cost-reduction-in-llm-applications-6c792a0ac29b) — Enterprise case study.
- [LLM Cost Optimization Guide — FutureAGI](https://futureagi.com/blogs/llm-cost-optimization-2025) — Infrastructure optimization.
- [Cost Optimization for LLM API Calls in Production — Medium](https://medium.com/@ajayverma23/taming-the-beast-cost-optimization-strategies-for-llm-api-calls-in-production-11f16dbe2c39) — Production strategies.
- [LLM API Pricing Guide](https://mobisoftinfotech.com/resources/blog/ai-development/llm-api-pricing-guide) — Token rates and model comparison.

---

## Section 14 — Observability & Monitoring

### Tools & Documentation
- [Langfuse — LLM Observability & Tracing](https://langfuse.com/docs/observability/overview) — Open-source observability platform.
- [Arize Phoenix — AI Observability](https://arize.com/docs/phoenix) — Open-source LLM monitoring.
- [Arize Phoenix — GitHub](https://github.com/Arize-ai/phoenix) — Source code and setup.
- [LlamaIndex Observability Module](https://developers.llamaindex.ai/python/framework/module_guides/observability/) — Built-in observability.

### Articles & Tutorials
- [LLM Monitoring and Observability with Langfuse — Towards Data Science](https://towardsdatascience.com/llm-monitoring-and-observability-hands-on-with-langfuse/) — Hands-on tutorial.
- [Langfuse vs. Arize Phoenix Comparison](https://langfuse.com/faq/all/best-phoenix-arize-alternatives) — Side-by-side comparison.
- [Comparing LLM Evaluation Platforms 2025 — Arize](https://arize.com/llm-evaluation-platforms-top-frameworks/) — Top frameworks compared.
- [Best LLM Observability Tools in 2025 — Firecrawl](https://www.firecrawl.dev/blog/best-llm-observability-tools) — Tool comparison guide.
- [Debugging and Tracing LLMs Like a Pro — Medium](https://rajeevbarnwal.medium.com/debugging-and-tracing-llms-like-a-pro-b560ded19fd9) — Phoenix + LangChain integration.
- [Top Open-Source LLM Observability Tools 2025 — Medium](https://medium.com/@thepracticaldeveloper/top-open-source-llm-observability-tools-in-2025-d2d5cbf4b932) — Open-source tool roundup.

---

## Section 15 — LLM Reasoning Failures

### Papers
- [Hallucination is Inevitable: An Innate Limitation of LLMs](https://arxiv.org/abs/2401.11817) — Theoretical proof that hallucination cannot be eliminated.
- [Survey of Hallucinations in LLMs: Principles, Taxonomy, Challenges](https://dl.acm.org/doi/10.1145/3703155) — ACM comprehensive survey.
- [Survey of Hallucination Attribution: Prompting vs Model Behavior](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1622292/full) — 2025 attribution analysis.
- [From Illusion to Insight: Hallucination Mitigation Techniques](https://www.mdpi.com/2673-2688/6/10/260) — Taxonomy of mitigation methods.
- [LLM-based Agents Suffer from Hallucinations: Survey](https://arxiv.org/html/2509.18970v1) — Agent-specific hallucination analysis.
- [Mitigating Hallucination: RAG, Reasoning, and Agentic Systems](https://arxiv.org/html/2510.24476v1) — Application-oriented survey.

---

## Section 16 — System Design

### Courses & Books
- [Building LLMs for Production — O'Reilly](https://www.oreilly.com/library/view/building-llms-for/9798324731472/) — Deployment, optimization, scaling.
- [Agentic AI System Design for PMs — Maven](https://maven.com/boring-bot/ml-system-design) — By Hamza Farooq and Gabriela de Queiroz.
- [AI Infrastructure Blueprint (2025-2026)](https://techitez.org/ai/llm-infrastructure-blueprint/) — Production architecture guide.
- [Full Stack AI Engineer 2026 — Udemy](https://www.udemy.com/course/full-stack-ai-engineer-2026-generative-ai-llms-iii/) — End-to-end AI engineering.

---

## Books

| Book | Author | Focus |
|:---|:---|:---|
| [Building LLMs for Production](https://www.oreilly.com/library/view/building-llms-for/9798324731472/) | O'Reilly | Deployment, quantization, speculative decoding |
| [Designing Machine Learning Systems](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/) | Chip Huyen | ML systems design, pipelines, monitoring |
| [10 Must-Read AI & LLM Engineering Books (2026)](https://dev.to/somadevtoo/10-must-read-ai-and-llm-engineering-books-for-developers-in-2025-129j) | DEV Community | Curated reading list |
| [10 AI Books Every Software Engineer Should Read](https://medium.com/javarevisited/10-books-every-software-engineer-should-read-to-become-an-ai-engineer-in-2025-1c721d595084) | Medium | Comprehensive book guide |

---

## Newsletters & Blogs

Stay current with the rapidly evolving AI landscape.

| Newsletter | Focus | Link |
|:---|:---|:---|
| **The Batch** | AI news by Andrew Ng / DeepLearning.AI | [deeplearning.ai](https://www.deeplearning.ai/the-batch/) |
| **TLDR AI** | Daily AI/ML news for 1.25M+ readers | [tldr.tech/ai](https://tldr.tech/ai) |
| **Latent Space** | AI engineering deep dives | [latent.space](https://www.latent.space/) |
| **Superhuman AI** | AI trends in 3 min/day, 1M+ readers | [superhuman.ai](https://www.superhuman.ai/) |
| **Ben's Bites** | Business AI use cases | [bensbites.co](https://www.bensbites.co/) |
| **The ML Engineer** | ML frameworks, tools, best practices | [ethical.institute](https://ethical.institute/mle.html) |
| **AI Weekly** | Weekly AI news roundup | [aiweekly.co](https://aiweekly.co/) |
| [Best AI Newsletters 2025](https://www.dataschool.io/best-ai-newsletters-in-2025/) | Curated list | Data School |
| [Top 10 AI Newsletters 2026](https://datanorth.ai/blog/top-10-ai-newsletters-to-follow-in-2026) | Updated list | DataNorth |
| [Awesome AI Newsletters — GitHub](https://github.com/alternbits/awesome-ai-newsletters) | Community-curated list | GitHub |

---

## DeepLearning.AI Short Courses

> All free, 1-2 hour courses.

| Course | Topic |
|:---|:---|
| [Retrieval Augmented Generation (RAG)](https://www.deeplearning.ai/courses/retrieval-augmented-generation-rag/) | RAG architecture and evaluation |
| [Building and Evaluating Advanced RAG](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/) | Advanced retrieval patterns |
| [Embedding Models: From Architecture to Implementation](https://www.deeplearning.ai/courses/) | Embedding internals |
| [Building AI Browser Agents](https://www.deeplearning.ai/courses/) | Web-based agents |
| [Building Code Agents with smolagents](https://www.deeplearning.ai/courses/) | Hugging Face agents |
| [DSPy: Build and Optimize Agentic Apps](https://www.deeplearning.ai/courses/) | DSPy framework |
| [Claude Code: A Highly Agentic Coding Assistant](https://www.deeplearning.ai/courses/) | Claude Code |
| [Building and Evaluating Data Agents](https://www.deeplearning.ai/courses/) | Data agent evaluation |
| [Building AI Voice Agents for Production](https://www.deeplearning.ai/courses/) | Voice agent systems |
| [Full course catalog](https://www.deeplearning.ai/courses/) | Browse all 100+ courses |

---

## Contributing

Contributions welcome! Please:
1. Open an issue for discussion
2. Submit PR with new questions
3. Include difficulty level and category
4. Add expected answer and red flags

---

## License

MIT License — Feel free to use for interview prep, team training, or educational purposes.

---

**Built with real-world experience from production AI systems in the MENA region.**

*Last updated: February 2026*

---

[← Previous: Red Flags](./red-flags.md) | [← Back to Main](../README.md)
